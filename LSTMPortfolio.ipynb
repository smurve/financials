{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-beta0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning from dice sequences\n",
    "This is a toy problem. Any sequence of 5 throws is rewarded with a particular value based on some prior *truth*. Ten different independent dice are being rewarded at the same time. \n",
    "\n",
    "Think of this as 5 consecutive days of trading in 10 different stocks. For each stock, there's one day where buying it will give an immediate reward. That reward is different for every stock and every day, based on the *mask* matrix below.\n",
    "\n",
    "We hope that the network learns when what stock to trade on what day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 3\n",
    "N_STEPS = 5\n",
    "N_FEATURES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N_STEPS consecutive samples with N_FEATURES dice. Each sequence of N_STEPS gets a score. E.g. the first die gets a tenth of what the first result was. So, each die (feature) is independent of the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.floor(np.random.random([BATCH_SIZE, N_STEPS, N_FEATURES]) * 7).astype(np.float32)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1, 0. , 0. , 0. , 0. , 0.5, 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0.2, 0. , 0. , 0. , 0. , 0.4, 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0.3, 0. , 0. , 0. , 0. , 0.3, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0.4, 0. , 0. , 0. , 0. , 0.2, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0.5, 0. , 0. , 0. , 0. , 0.1]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.zeros((5,10), dtype=np.float32)\n",
    "\n",
    "for k in range(5):\n",
    "    mask[k][k]=(k+1)/10.\n",
    "    mask[k][k+5]=.6-(k+1)/10.\n",
    "\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truth(x):\n",
    "    logits = np.round(np.sum(x * mask, axis=0), 3)\n",
    "    e = np.exp(logits)\n",
    "    return e / np.sum(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0427836 , 0.05225601, 0.05225601, 0.06382563, 0.34937814,\n",
       "       0.12852903, 0.14204656, 0.0387122 , 0.0779568 , 0.05225601],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic\n",
    "Try to just mimic the truth function, let it find out the mask values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense__trade_model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             multiple                  510       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             multiple                  704       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             multiple                  650       \n",
      "=================================================================\n",
      "Total params: 1,864\n",
      "Trainable params: 1,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class Heuristic_TradeModel(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(Heuristic_TradeModel, self).__init__()\n",
    "        self.selector = layers.Dense(\n",
    "            10, activation='relu', \n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.1))\n",
    "        self.denses = [layers.Dense(u, activation='relu') for u in units]\n",
    "        self.logits = layers.Dense(10, activation = None)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        out = tf.cast(inputs / 100, dtype=tf.float32)\n",
    "        out = tf.reshape(out, shape=[-1, 50])\n",
    "        out = self.selector(out)\n",
    "        for layer in self.denses:\n",
    "            out = layer(out) \n",
    "        out = self.logits(out)\n",
    "        return out\n",
    "    \n",
    "    def portfolio(self, inputs):\n",
    "        return activations.softmax(self.call(inputs))\n",
    "\n",
    "model = Heuristic_TradeModel([64])\n",
    "x = np.floor(np.random.random(\n",
    "    [BATCH_SIZE, N_STEPS, N_FEATURES]) * 7).astype(np.float32)\n",
    "\n",
    "_ = model(x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM and Dense Model \n",
    "...just don't work!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense__trade_model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             multiple                  510       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             multiple                  704       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             multiple                  650       \n",
      "=================================================================\n",
      "Total params: 1,864\n",
      "Trainable params: 1,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class Dense_TradeModel(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(Dense_TradeModel, self).__init__()\n",
    "        self.selector = layers.Dense(\n",
    "            10, activation='relu', \n",
    "            kernel_regularizer=tf.keras.regularizers.l2(l=0.1))\n",
    "        self.denses = [layers.Dense(u, activation='relu') for u in units]\n",
    "        self.logits = layers.Dense(10, activation = None)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        out = tf.cast(inputs / 100, dtype=tf.float32)\n",
    "        out = tf.reshape(out, shape=[-1, 50])\n",
    "        out = self.selector(out)\n",
    "        for layer in self.denses:\n",
    "            out = layer(out) \n",
    "        out = self.logits(out)\n",
    "        return out\n",
    "    \n",
    "    def portfolio(self, inputs):\n",
    "        return activations.softmax(self.call(inputs))\n",
    "\n",
    "model = Dense_TradeModel([64])\n",
    "x = np.floor(np.random.random(\n",
    "    [BATCH_SIZE, N_STEPS, N_FEATURES]) * 7).astype(np.float32)\n",
    "\n",
    "_ = model(x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm__trade_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  multiple                  71168     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 72,458\n",
      "Trainable params: 72,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class LSTM_TradeModel(tf.keras.Model):\n",
    "    def __init__(self, n_neurons):\n",
    "        super(LSTM_TradeModel, self).__init__()\n",
    "        self.lstm = layers.LSTM(\n",
    "            n_neurons, \n",
    "            input_shape=[None, 5, 10],\n",
    "            return_sequences=False)\n",
    "        self.logits = layers.Dense(10, activation = None)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        out = tf.cast(inputs / 100, dtype=tf.float32)\n",
    "        out = self.lstm(out) \n",
    "        out = self.logits(out)\n",
    "        return out\n",
    "    \n",
    "    def portfolio(self, inputs):\n",
    "        return activations.softmax(self.call(inputs))\n",
    "\n",
    "model = LSTM_TradeModel(128)\n",
    "x = np.floor(np.random.random(\n",
    "    [BATCH_SIZE, N_STEPS, N_FEATURES]) * 7).astype(np.float32)\n",
    "\n",
    "_ = model(x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09941742, 0.09997836, 0.10062797, 0.10010673, 0.09946124,\n",
       "        0.10159553, 0.09931004, 0.09972215, 0.09942178, 0.10035885],\n",
       "       [0.09942142, 0.09965046, 0.1002036 , 0.10077167, 0.09883868,\n",
       "        0.10254937, 0.09884752, 0.09973002, 0.09971128, 0.1002759 ],\n",
       "       [0.09942549, 0.09944106, 0.10058582, 0.10089849, 0.09837616,\n",
       "        0.10421751, 0.09801126, 0.09959725, 0.09978559, 0.09966137]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.portfolio(x).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_data_set(n_steps, n_features, total_size,\n",
    "                 batch_size, buffer_size=1000):\n",
    "    def _generator():\n",
    "        x = np.floor( np.random.random(\n",
    "                [n_steps, n_features]) * 7).astype(np.float32)\n",
    "        y = truth(x)\n",
    "        for _ in range(total_size):\n",
    "            yield x,y\n",
    "\n",
    "    inputs = tf.data.Dataset.from_generator(\n",
    "        _generator, output_types = (tf.float32, tf.float32))\n",
    "\n",
    "    inputs = inputs.shuffle(buffer_size).batch(batch_size)\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = new_data_set(5, 10, 1000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=20177, shape=(1, 5, 10), dtype=float32, numpy=\n",
       " array([[[0., 6., 6., 4., 2., 3., 0., 4., 0., 3.],\n",
       "         [0., 6., 6., 2., 4., 5., 0., 3., 5., 6.],\n",
       "         [1., 0., 3., 2., 6., 0., 1., 5., 1., 5.],\n",
       "         [2., 4., 5., 3., 5., 6., 3., 4., 0., 5.],\n",
       "         [2., 6., 3., 2., 1., 6., 6., 4., 6., 4.]]], dtype=float32)>,\n",
       " <tf.Tensor: id=20178, shape=(1, 10), dtype=float32, numpy=\n",
       " array([[0.04131589, 0.1371736 , 0.1016207 , 0.1371736 , 0.06811839,\n",
       "         0.18516497, 0.04131589, 0.18516497, 0.04131589, 0.06163607]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - 5s 233ms/step - loss: 2.2046\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 5s 233ms/step - loss: 2.1954\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 5s 228ms/step - loss: 2.2771\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 5s 232ms/step - loss: 2.3941\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 5s 230ms/step - loss: 2.2210\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 5s 234ms/step - loss: 2.1072\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 5s 231ms/step - loss: 2.2139\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 5s 234ms/step - loss: 2.0413\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 5s 237ms/step - loss: 2.4155\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 5s 231ms/step - loss: 2.0789\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 5s 231ms/step - loss: 2.2822\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 5s 233ms/step - loss: 2.2689\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 5s 230ms/step - loss: 2.3215\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 5s 235ms/step - loss: 2.1970\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 5s 231ms/step - loss: 2.1032\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 5s 233ms/step - loss: 2.1081\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 5s 231ms/step - loss: 2.4058\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 5s 233ms/step - loss: 2.2490\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 5s 236ms/step - loss: 2.2156\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 5s 232ms/step - loss: 2.0291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e4d13af470>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = new_data_set(5, 10, 100000, 5000)\n",
    "model.fit(dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 0s 15ms/step - loss: 2.1762"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1762139797210693"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(new_data_set(5, 10, 100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=27496, shape=(1, 5, 10), dtype=float32, numpy=\n",
       " array([[[3., 6., 6., 0., 4., 2., 3., 4., 1., 2.],\n",
       "         [2., 2., 5., 4., 6., 1., 2., 4., 4., 1.],\n",
       "         [1., 3., 5., 6., 2., 2., 4., 0., 2., 1.],\n",
       "         [0., 0., 2., 2., 5., 3., 3., 1., 1., 3.],\n",
       "         [5., 0., 3., 5., 1., 2., 2., 3., 5., 5.]]], dtype=float32)>,\n",
       " <tf.Tensor: id=27497, shape=(1, 10), dtype=float32, numpy=\n",
       " array([[0.06745388, 0.07454807, 0.22395477, 0.11121264, 0.08238835,\n",
       "         0.13583542, 0.11121264, 0.04997106, 0.06103479, 0.08238835]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = new_data_set(5, 10, 1000, 1)\n",
    "x, y = next(iter(dataset))\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=27518, shape=(1, 10), dtype=float32, numpy=\n",
       "array([[0.04695836, 0.05248175, 0.07947842, 0.12919323, 0.19288217,\n",
       "        0.11984455, 0.16159499, 0.09934296, 0.06611667, 0.05210704]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.portfolio(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
